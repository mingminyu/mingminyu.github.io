---
date: 2025-06-15
authors:
  - mingminyu
categories:
  - 商业分析
tags:
  - 转载
slug: think-ab-test-from-scractch
readtime: 20
---

# 从0到1读懂AB实验：数据驱动决策的统计底层逻辑

> 原文地址：https://mp.weixin.qq.com/s/ha0B0ic4mYbo-fAf4c-95w

![](https://mingminyu.github.io/webassets/images/20250615/26.png)

在工作中，经常会有产品同学和运营同学问我：“某某AB实验数据出来了，应该怎么理解？”，“为什么A组CTR比B组高2%，但是为什么说不置信？” 最近一些技术同学甚至有些算法同学也来探讨类似的问题，这让我有些惊讶。平时工作中，大家默认AB是合理的且必不可少的，都知道用AB来验证自己的想法，但AB的数据结果的理解又含糊不清。

<!-- more -->

在有些大厂，设有专门的实验科学委员会，有专门的数据同学把控实验流程，从实验验证提出，流量科学划分，到打点计算，数据统计，结论分析有专人负责。但大部分公司都没有人力专门负责这一套，能搭建一套AB分流系统已经不容易了。

本篇主要介绍我理解的AB实验数据分析如何科学合理，尽量少用公式，用大白话说清楚。本篇预设阅读对象是关注AB实验的小白，如果是大神请出门左转，看看自动化分析算法应用或者桃花源没事儿。

## 1. 为什么需要AB实验?

AB测试方法的起源远早于互联网：随机对照试验（RCT）的概念在医学、农业、社会科学等领域已有悠久历史（可追溯到Ronald Fisher等统计学家在20世纪初的工作）。

互联网公司AB实验的发展里程碑无疑是谷歌2010年那篇《Overlapping Experiment Infrastructure: More, Better, Faster》，这篇文章奠定了大规模数据分流的科学基础，各大厂都是基于此迭代优化搭建的AB系统。可见AB测试在医学、社科领域有几十年的历史，在互联网公司也有20年的历史，AB实验的重要性毋庸置疑。

!!! quote "历史中的AB测试"

    《长安的荔枝》中，李善德在岭南往长安运荔枝的时候，也会同时对比多个路线，用列联表记录效果。可惜他没用显著性检验，荔枝坏了就是坏了，不需要算坏了50%，还是100%。

我认为，AB实验可以创造出”平行世界”，并在不同的世界验证你的天马行空的想法。

## 2. AB实验的理论基础：抽样分布、假设检验、中心极限定理

比如医药公司随机招募1000名符合条件的患者随机分成两个组，其中干预组 500 名患者服用新型药物，对照组 500名患者服用标准药物。又比如互联网公司通过AB系统进行分流，某实验50%对50%或10%对90%切分实验对照。

各行业的AB实验都是基于统计学中的抽样分布，理论基础均为中心极限定理（Central Limit Theorem, CLT），用的工具为假设检验（Hypothesis Testing）。

为什么必须要抽样？因为你不可能真的创造一个平行时空，公司APP有1000万DAU，你不能在这个世界对100万用户上开屏A，在另一个世界对100万用户上开屏B。你只能尽力模拟平行世界，随机抽样50万 VS. 50万，只要涉及到抽样，就必须用到中心极限定理和假设检验。

我们把50%流量中每一个用户当做一个某总体分布的一个观测样本，比如我作为用户命中今日头条APP中某个实验，我的点击量或CTR都是这50%流量（假设有10万用户）中的一个计算样本，其他99999个用户跟我一样，划到一个集合进行计算。

我们10万个用户的作为一个抽样整体的均值（比如点击量）符合正态分布，这就是中心极限定理。无论变量符合什么分布，抽样整体的均值符合正态分布。所以实验的关键点是样本的均值，无论是连续型指标（点击量）还是比例型指标（点击率）。

假如，我们这10万用户是策略A，具体为是内容流里加入了《长安的荔枝》的切片视频，策略B是无《长安的荔枝》内容。实验假设是在长安的荔枝热播的时候，通过蹭热点，提升点击量。

- 假设H0：策略无效，A的人均点击和B的人均点击无差异；
- 假设H1：策略有效，A的人均点击和B的人均点击有明显差异。

最终的结果A的人均点击量4.2，B的人均点击量为4.1。

如果肉眼看的话 4.2 > 4.1，好像是 A赢了，策略有效。如果统计假设来看，Z=1.58（假设A和B标准差都是10，样本为10万），根据假设检验理论，A比B并没有显著差异，不能拒绝假设 **H0：策略无效**。

$$
Z = \frac{\Delta}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}
$$

所以 $Z$ 就是 $\Delta$ 除以标准差。

## 3. AB实验的核心概念：置信度、置信区间、统计功效、最小样本量、统计效应

**置信度**：也称为显著性水平，默认 95%，也就是常说的 $\alpha$=1-95%=0.05,$\alpha$ 又被假设检验的第一类错误（“去真”）。举个例子，某工厂生产的玩具次品率为 5%，我们做抽样检测时，假设 H0 次品率为 5%，备选假设 H1 为次品率超过 5%；已知抽到次品率的概率为 5%，如果抽到了次品，那么小概率事件发生，我们认为 H0 不对，选择 H1。但事实上，我们的确有 5% 的小概率抽到次品，这时候我们的假设检验结果是错误的，”去真”，是真的，你拒绝。

**置信区间**：置信区间是通过统计量做上限、下限的计算，可以观测实验结果的波动幅度。

常见错误理解：不是样本均值有95%的概率落到置信区间里。因为样本均值是做总体均值的统计推断结果，总体均值是一个固定真实的值，不存在概率的说法。比如小名的体重70公斤，不能说他的体重有95%的概率略到60-80的区间。

正确的说法是：做100次抽样，有100个统计置信区间，其中有95%包含了那个原有的固定的真实的值。

对于均值 $\hat x$，若样本来自正态总体，或 $n$ 较大，置信区间为：

$$
\bar{x} \pm Z_{1-\alpha/2} \cdot \sqrt{\frac{\sigma}{n}}
$$

或者当你不知道总体方差，用样本方差 $s$ ：

$$
\bar{x} \pm t_{n-1,1-\alpha/2} \cdot \sqrt{\frac{s}{n}}
$$

**统计功效**：统计功效和置信度是一对兄弟，必须绑定出现。只是置信度知名度更高一些。

常用的统计功效为 0.8，也就是常说的 $\beta$=1-0.8=20%。$\beta$ 又被假设检验的第二类错误（“存伪”）。比如某工厂生产的玩具次品率为 20%，我们做抽样检测时，假设 H0 次品率为 5%，备选假设H1为次品率超过5%；我们有80%的概率抽到正品，这时我们没有办法拒绝H0，只能选择接受 H0。但事实上次品率为 20%，远超过5%。这就是存伪了，是假的，你不拒绝。这时候beta高达80%，远远不合理。因为我们只假设抽样一次，我们如果抽10次，beta会下降很明显（从80%降到11%）。所以样本量是非常重要概念。

**最小样本量**：样本量n非常重要，从上述公式可以看到，它和Z统计量呈正比，样本量越大Z可能越大。在 AB 实验中，因为每一次分流，每一个样本都是机会成本，你在某短时间参与了实验 A，就无法参与另一个实验。（实验分层和实验互斥的事是另一个个事情，这里简单起见仅作互斥假设）；所以我们具体关注的最小样本量。最小样本量的推导过程非常经典，理解了这个就理解了假设检验。推导过程刚好用到了前面的置信度和统计功效：

![](https://mingminyu.github.io/webassets/images/20250615/27.png)

蓝色曲线为 H0，标准正态分布，蓝色虚线为H0均值；红色曲线为 H1，正态分布，蓝色虚线为H1均值；

H1均值-H0均值的差值必须要足够大，大的满足两个条件：

1. 满足置信度条件，$\alpha$=0.05，即让图中灰色虚线切分的在**蓝色曲线**中的中的蓝色区域面积>0.05；
2. 满足统计功效条件，$\alpha$=0.8，即让图中灰色虚线切分的在**红色曲线**中的中的红色区域面积>0.05；**这里有一点比较难理解，我们假设H1均值比H0均值的差值是置信的，那H1的分布就和H0不同，此时必须用H1红色曲线的面积。**

满足上述条件后，可以得到最小样本量不等式：

![](https://mingminyu.github.io/webassets/images/20250615/28.png)

所以样本量$n$和$\Delta$是两个相关变量，在实际AB情况中，$\Delta$是需要根据实验假设设定的值，进而推导出最小样本量$n$。比如我希望点击量均值至少提升5%，CTR至少提升1%等等。

比如上面《长安的荔枝》内容分发的例子来看，最终的结果A的人均点击量 4.2，B的人均点击量为 4.1。


如果想让 4.2>4.1置 信,则至少需要样本量：每组样本量为 156978，总样本量为 313956。所以假设中的10万样本量不够。
最小样本量$n$的计算公式，是严格按照CLT的正态分布算出来的，假如样本分布不均（严重左偏是常有的事），或者有极端异常值，那么n的计算就会有偏差，此时必须要做异常值处理。

**统计效应：**在结果置信时，还需要考虑真实的业务提升。统计功效就是这个用途。如果一个实验从4.1提升到4.2,即使统计一样上置信，对业务的提升能有多大帮助呢？再极端一点，从4.1提升到4.11，样本量156万时统计上置信，对业务的提升基本没帮助。实验的收益完全不符合业务要求。此时就要看统计效应的大小。具体计算公式和结果大小选择如下图：

![](https://mingminyu.github.io/webassets/images/20250615/29.png)

上图 4.2 和 4.1 的统计效应只有 0.001（假设标准差为 10），远低于0.1的最小阈值，即使实验结果置信，也不可取。

关于统计效应的进一步理解：

1. 对于连续型指标的统计效应d，如下图，两个曲线的重合部分越小，d越高。其实就是最小样本量的H1均值-H0均值距离越大，越好；


![](https://mingminyu.github.io/webassets/images/20250615/30.png)

2. **比率型指标统计效应h**，如下图，$\arcsin(\sqrt{p})$ 是对比例类数据的**方差稳定变换**，让差值在所有区域都更具可比性；得到的$h$是无量纲的、可标准化的指标。如果直接对比，比如比率**的差异****在线性尺度下不公平**；低值区域（0.1 vs. 0.2 提升 100%）对差异更敏感，高值区域不明显（0.8 vs. 0.9 提升 12.5%）。

![](https://mingminyu.github.io/webassets/images/20250615/31.png)

## 4. AB实验结论理解

置信度有了，统计效应也有了，我们可以很科学的得出数据结论。如果一个实验的数据通过了所有的检验条件，是不是就万事大吉了，直接放量就行了吗？显然不是。

**实验最终的目的，是做出一个又一个假设，不断地验证迭代，进而去更好的理解用户和提升业务**。实验数据结果验证只是中间的一步，更重要的是实验指标为什么涨了？**下一步要基于实验数据做因果推断，明确实验策略对业务的影响链路**。

要做到这一步，必须从头开始，实验创建前的假设策略池的搭建，策略的优先级，策略相互的影响，如果策略A成了，代表什么，下一步该上哪个策略更适合。实验的反哺策略池，最终形成产品知识库。
