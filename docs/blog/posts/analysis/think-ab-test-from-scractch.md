---
date: 2025-06-15
authors:
  - mingminyu
categories:
  - 商业分析
tags:
  - 转载
slug: think-ab-test-from-scractch
readtime: 20
---

# 从0到1读懂AB实验：数据驱动决策的统计底层逻辑

> 原文地址：https://mp.weixin.qq.com/s/ha0B0ic4mYbo-fAf4c-95w

![](https://mingminyu.github.io/webassets/images/20250615/26.png)

在工作中，经常会有产品同学和运营同学问我：“某某AB实验数据出来了，应该怎么理解？”，“为什么A组CTR比B组高2%，但是为什么说不置信？” 最近一些技术同学甚至有些算法同学也来探讨类似的问题，这让我有些惊讶。平时工作中，大家默认AB是合理的且必不可少的，都知道用AB来验证自己的想法，但AB的数据结果的理解又含糊不清。

<!-- more -->

在有些大厂，设有专门的实验科学委员会，有专门的数据同学把控实验流程，从实验验证提出，流量科学划分，到打点计算，数据统计，结论分析有专人负责。但大部分公司都没有人力专门负责这一套，能搭建一套AB分流系统已经不容易了。

本篇主要介绍我理解的AB实验数据分析如何科学合理，尽量少用公式，用大白话说清楚。本篇预设阅读对象是关注AB实验的小白，如果是大神请出门左转，看看自动化分析算法应用或者桃花源没事儿。

## 1. 为什么需要AB实验?

AB测试方法的起源远早于互联网：随机对照试验（RCT）的概念在医学、农业、社会科学等领域已有悠久历史（可追溯到Ronald Fisher等统计学家在20世纪初的工作）。

互联网公司AB实验的发展里程碑无疑是谷歌2010年那篇《Overlapping Experiment Infrastructure: More, Better, Faster》，这篇文章奠定了大规模数据分流的科学基础，各大厂都是基于此迭代优化搭建的AB系统。可见AB测试在医学、社科领域有几十年的历史，在互联网公司也有20年的历史，AB实验的重要性毋庸置疑。

!!! quote "历史中的AB测试"

    《长安的荔枝》中，李善德在岭南往长安运荔枝的时候，也会同时对比多个路线，用列联表记录效果。可惜他没用显著性检验，荔枝坏了就是坏了，不需要算坏了50%，还是100%。

我认为，AB实验可以创造出”平行世界”，并在不同的世界验证你的天马行空的想法。

## 2. AB实验的理论基础：抽样分布、假设检验、中心极限定理

比如医药公司随机招募1000名符合条件的患者随机分成两个组，其中干预组 500 名患者服用新型药物，对照组 500名患者服用标准药物。又比如互联网公司通过AB系统进行分流，某实验50%对50%或10%对90%切分实验对照。

各行业的AB实验都是基于统计学中的抽样分布，理论基础均为中心极限定理（Central Limit Theorem, CLT），用的工具为假设检验（Hypothesis Testing）。

为什么必须要抽样？因为你不可能真的创造一个平行时空，公司APP有1000万DAU，你不能在这个世界对100万用户上开屏A，在另一个世界对100万用户上开屏B。你只能尽力模拟平行世界，随机抽样50万 VS. 50万，只要涉及到抽样，就必须用到中心极限定理和假设检验。

我们把50%流量中每一个用户当做一个某总体分布的一个观测样本，比如我作为用户命中今日头条APP中某个实验，我的点击量或CTR都是这50%流量（假设有10万用户）中的一个计算样本，其他99999个用户跟我一样，划到一个集合进行计算。

我们10万个用户的作为一个抽样整体的均值（比如点击量）符合正态分布，这就是中心极限定理。无论变量符合什么分布，抽样整体的均值符合正态分布。所以实验的关键点是样本的均值，无论是连续型指标（点击量）还是比例型指标（点击率）。

假如，我们这10万用户是策略A，具体为是内容流里加入了《长安的荔枝》的切片视频，策略B是无《长安的荔枝》内容。实验假设是在长安的荔枝热播的时候，通过蹭热点，提升点击量。

- 假设H0：策略无效，A的人均点击和B的人均点击无差异；
- 假设H1：策略有效，A的人均点击和B的人均点击有明显差异。

最终的结果A的人均点击量4.2，B的人均点击量为4.1。

如果肉眼看的话 4.2 > 4.1，好像是 A赢了，策略有效。如果统计假设来看，Z=1.58（假设A和B标准差都是10，样本为10万），根据假设检验理论，A比B并没有显著差异，不能拒绝假设 **H0：策略无效**。

$$
Z = \frac{\Delta}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}
$$

所以 $Z$ 就是 $\Delta$ 除以标准差。

## 3. AB实验的核心概念：置信度、置信区间、统计功效、最小样本量、统计效应

**置信度**：也称为显著性水平，默认 95%，也就是常说的 $\alpha$=1-95%=0.05,$\alpha$ 又被假设检验的第一类错误（“去真”）。举个例子，某工厂生产的玩具次品率为 5%，我们做抽样检测时，假设 H0 次品率为 5%，备选假设 H1 为次品率超过 5%；已知抽到次品率的概率为 5%，如果抽到了次品，那么小概率事件发生，我们认为 H0 不对，选择 H1。但事实上，我们的确有 5% 的小概率抽到次品，这时候我们的假设检验结果是错误的，”去真”，是真的，你拒绝。

**置信区间**：置信区间是通过统计量做上限、下限的计算，可以观测实验结果的波动幅度。

常见错误理解：不是样本均值有95%的概率落到置信区间里。因为样本均值是做总体均值的统计推断结果，总体均值是一个固定真实的值，不存在概率的说法。比如小名的体重70公斤，不能说他的体重有95%的概率略到60-80的区间。

正确的说法是：做100次抽样，有100个统计置信区间，其中有95%包含了那个原有的固定的真实的值。

对于均值 $\hat x$，若样本来自正态总体，或 $n$ 较大，置信区间为：

$$
\bar{x} \pm Z_{1-\alpha/2} \cdot \sqrt{\frac{\sigma}{n}}
$$

或者当你不知道总体方差，用样本方差 $s$ ：

$$
\bar{x} \pm t_{n-1,1-\alpha/2} \cdot \sqrt{\frac{s}{n}}
$$

**统计功效**：统计功效和置信度是一对兄弟，必须绑定出现。只是置信度知名度更高一些。

常用的统计功效为 0.8，也就是常说的 $\beta$=1-0.8=20%。beta又被假设检验的第二类错误（“存伪”）。比如某工厂生产的玩具次品率为20%，我们做抽样检测时，假设H0次品率为5%，备选假设H1为次品率超过5%；我们有80%的概率抽到正品，这时我们没有办法拒绝H0，只能选择接受H0。但事实上次品率为20%，远超过5%。这就是存伪了，是假的，你不拒绝。这时候beta高达80%，远远不合理。因为我们只假设抽样一次，我们如果抽10次，beta会下降很明显（从80%降到11%）。所以样本量是非常重要概念。

**最小样本量**：样本量n非常重要，从上述公式可以看到，它和Z统计量呈正比，样本量越大Z可能越大。在AB实验中，因为每一次分流，每一个样本都是机会成本，你在某短时间参与了实验A，就无法参与另一个实验。（实验分层和实验互斥的事是另一个个事情，这里简单起见仅作互斥假设）；所以我们具体关注的最小样本量。最小样本量的推导过程非常经典，理解了这个就理解了假设检验。推导过程刚好用到了前面的置信度和统计功效：

![](https://mingminyu.github.io/webassets/images/20250615/27.png)
