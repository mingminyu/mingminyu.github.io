---
date: 2025-11-11
authors:
  - mingminyu
categories:
  - 风控模型
tags:
  - 特征选择
slug: feature-selection-with-ks-iv
readtime: 20
---

# 特征筛选：IV 和 KS

在金融风控领域，变量筛选是模型构建中至关重要的一环。面对成千上万的候选变量，如何精准筛选出 **预测能力强、稳定性高** 的变量，直接决定了风控模型的性能上限。

<!-- more -->

## 1. 变量筛选的意义：为什么不能“来者不拒”？

在风控模型开发中，我们经常会遇到数百甚至数千个候选变量，但并不是所有变量都适合进入模型。

变量过多会带来四大问题：

1. **过拟合风险**：变量过多会导致模型过度适应训练数据，而在新数据上表现不佳
2. **计算复杂度高**：不必要的变量增加了计算资源消耗和响应时间
3. **模型解释性差**：变量过多会使模型变得难以理解和解释
4. **运营成本高**：上线后需要持续监控和维护大量变量，增加运营成本

因此，**变量筛选** 成为风控模型构建中不可或缺的环节。而在众多筛选指标中，IV 值和 KS 值无疑是最为重要且常用的两个指标。

## 2. IV值：变量预测能力的“度量衡”

### 2.1 什么是 IV 值？

IV（Information Value，信息价值）是评估变量预测能力的重要指标，它衡量了一个变量对目标变量（如是否违约）的预测能力。

**IV值的数学原理**：

IV值源于信息论中的KL散度（Kullback-Leibler Divergence），衡量的是在知道该变量的信息后，对目标变量分布的“信息增益”。

计算公式：$$ \text{IV} = \sum((好客户占比 - 坏客户占比) * \text{WOE}) $$

其中 WOE（Weight of Evidence）的计算公式为：$$ \text{WOE} = \ln(好客户占比 / 坏客户占比)$$

### 2.2 IV值的评价标准

一般来说，IV值的解释能力如下：

| IV值范围 | 预测能力 |
| -------- | -------- |
| IV < 0.02 | 无意义 |
| 0.02 ≤ IV < 0.1 | 预测能力较弱 |
| 0.1 ≤ IV < 0.3 | 预测能力中等 |
| 0.3 ≤ IV | 预测能力强 |

### 2.3 IV值计算实例

假设我们有一个“年龄”变量，想要评估其对客户是否违约的预测能力：

| 年龄分段 | 好客户数 | 坏客户数 | 好客户占比 | 坏客户占比 | WOE     | IV贡献 |
| -------- | -------- | -------- | ---------- | ---------- | ------- | ------ |
| <25      | 150      | 50       | 0.15       | 0.25       | -0.5108 | 0.0511 |
| 25-35    | 300      | 60       | 0.30       | 0.30       | 0.0000  | 0.0000 |
| 35-45    | 350      | 40       | 0.35       | 0.20       | 0.5596  | 0.0839 |
| 45-55    | 150      | 30       | 0.15       | 0.15       | 0.0000  | 0.0000 |
| >55      | 50       | 20       | 0.05       | 0.10       | -0.6931 | 0.0347 |

**总IV值** = 0.0511 + 0.0000 + 0.0839 + 0.0000 + 0.0347 = **0.1697**

根据 IV 评价标准，此年龄变量的IV值为 0.1697，属于 **预测能力中等** 的变量，可以考虑进入模型。

### 2.4 IV值的优势与局限

**优势**：

- 能够全面评估变量的预测能力
- 对单调和非单调关系都敏感
- 提供了明确的评价标准

**局限**：

- 对分箱方式敏感
- 无法评估变量的方向性
- 可能受到极端值影响

## 3. KS值：变量区分能力的“试金石”

!!! question "KS 到底代表了什么？"

    模型在现有变量的基础上，加入了一个变量后 KS 上升了 1 个点，但是 AUC 却保持不变，这是为啥？

### 3.1 什么是KS值？

KS（Kolmogorov-Smirnov）值用于衡量一个变量对好客户和坏客户的 **区分能力**，它表示的是好客户和坏客户累积分布的最大差异。

### 3.2 KS值的计算原理

KS值的计算过程：

1. 将变量按大小排序并分箱（通常10-20箱）
2. 计算每个分箱内好客户和坏客户的累积分布
3. 计算每个分箱内好坏客户累积分布的绝对差值
4. 取最大绝对差值作为KS值

KS值的评价标准：

| KS值范围 | 分区能力 |
| -------- | -------- |
| KS < 0.2 | 区分能力较弱 |
| 0.2 ≤ KS < 0.3 | 区分能力一般 |
| 0.3 ≤ KS < 0.5 | 区分能力较强 |
| KS ≥ 0.5 | 区分能力极强 |

### 3.3 KS值计算实例

继续使用上面的年龄例子：

| 年龄分段 | 好客户累积分布 | 坏客户累积分布 | 累积分布差 |
| -------- | -------------- | -------------- | ---------- |
| <25      | 0.15           | 0.25           | 0.10       |
| 25-35    | 0.45           | 0.55           | 0.10       |
| 35-45    | 0.80           | 0.75           | 0.05       |
| 45-55    | 0.95           | 0.90           | 0.05       |
| >55      | 1.00           | 1.00           | 0.00       |

**KS值** = **0.10**（最大累积分布差）

此年龄变量的 KS 值为 0.10，表示 **区分能力较弱**。与 IV 值的结论（预测能力中等）相比，KS 值给出了更为保守的评价。

### 3.4 KS值的优势与局限

**优势**：

- 直观易懂，解释性强
- 对模型区分能力有直接指示作用
- 不受变量单调性影响

**局限**：

- 只关注最大差异，可能忽略变量的整体区分模式
- 对分箱方式敏感
- 样本量较小时可靠性降低

## 4. IV值与KS值的协同应用

在实际风控建模中，IV 值和 KS 值应该 **结合使用**，互相补充。

### 4.1 协同筛选策略

1. **初筛阶段**：使用 IV 值进行初步筛选，剔除 IV 值低于 0.02 的变量
2. **精筛阶段**：结合 IV 值和 KS 值，选择IV值较高且 KS 值也较高的变量
3. **交叉验证**：对于 IV 值和 KS 值结论不一致的变量，需要进一步分析原因

### 4.2 实际应用案例

假设我们正在构建个人信贷风控模型，现有以下候选变量：

| 变量名称        | IV值 | KS值 | 评价           |
| --------------- | ---- | ---- | -------------- |
| 近3个月逾期次数 | 0.45 | 0.52 | 优秀，强烈推荐 |
| 年龄            | 0.17 | 0.10 | 中等，可考虑   |
| 年收入          | 0.25 | 0.35 | 良好，推荐     |
| 教育水平        | 0.08 | 0.15 | 较弱，谨慎使用 |
| 职业类型        | 0.05 | 0.12 | 弱，不建议使用 |
| 地理位置        | 0.01 | 0.03 | 无意义，剔除   |

决策分析：

- **近3个月逾期次数**：IV值和KS值均很高，是 **强预测变量**，应优先入选
- **年收入**：IV值和KS值都不错，是 **良好预测变量**，应入选
- **年龄**：IV值中等但 KS 值较低，需要进一步分析——可能是由于年龄与违约风险存在 **非单调关系**，导致KS值较低但IV值尚可
- **教育水平** 和 **职业类型**：预测能力较弱，可根据模型需要决定是否保留
- **地理位置**：预测能力无意义，直接剔除

### 4.3 矛盾情况处理

当IV值和KS值给出矛盾信号时，我们需要深入分析：

情况一：高IV值、低KS值

: 通常表明变量与目标变量存在 **强关联但非单调** 的关系。例如，年龄与违约风险可能呈现 U 型曲线——年轻人和老年人违约风险高，中年人风险低。
: 处理方式：考虑使用分段函数或非线性变换来处理此类变量。

情况二：低IV值、高KS值

: 较少见，通常表明变量在 **某一特定区间** 有强区分能力，但整体区分能力不足。
: 处理方式：可考虑将该变量与其他变量组合使用，或作为规则模型的变量。

## 5. 实践中的注意事项

### 5.1 分箱的重要性

IV值和KS值的计算都依赖于变量的分箱。不合理的分箱会导致指标失真。

分箱原则：

- 确保每箱有足够的样本量
- 保持单调性或业务逻辑合理性
- 箱数不宜过多或过少（通常5-20箱）
- 避免过于均衡或极端不平衡的分箱

### 5.2 稳定性的考量

除了预测能力，变量的 **稳定性** 也是筛选的重要考量因素。我们可以使用 PSI（Population Stability Index）来评估变量的稳定性。

稳定性要求：

- 变量在不同时间段的分布应保持相对稳定
- 变量在训练集和测试集上的表现应一致
- 变量在跨人群应用时应有相似的预测能力

### 5.3 业务逻辑的符合性

技术指标再好的变量，也必须 **符合业务逻辑**。例如：

- 变量与风险之间的因果关系应合理
- 变量不应存在道德或法律问题
- 变量应具有可解释性

## 6 未来发展趋势

随着人工智能技术的发展，变量筛选方法也在不断进化：

1. **自动化变量筛选**：基于机器学习算法自动筛选和组合变量
2. **深度学习应用**：利用神经网络自动学习变量表示和交互
3. **可解释性AI**：在保持预测能力的同时增强模型可解释性
4. **实时变量筛选**：适应线上实时风控的场景需求

## 7. 结语

IV值和KS值作为风控模型变量筛选的 **核心指标**，为我们在海量变量中寻找真正有预测能力的特征提供了科学依据。然而，技术指标并非万能，必须与 **业务理解** 和 **实践经验** 相结合。

优秀的风险建模师不仅能够熟练计算这些指标，更能理解其背后的统计原理和业务含义，在技术与业务之间找到最佳平衡点。

在智能风控的道路上，掌握 IV 值和 KS 值的双重密码，只是第一步，却是构建高效、稳定、可解释风控模型的关键一步。
