---
date: 2025-09-01
authors:
  - mingminyu
categories:
  - 金融风控
tags:
  - 转载
  - 风控模型
slug: model-dev-and-evaluation
readtime: 2
---

# 模型开发与评估

> 原文地址：https://mp.weixin.qq.com/s/OiHNIv7KpfrPn_zVvjtIYA

在[【风控模型专题：一文了解模型变量特征工程】](https://mp.weixin.qq.com/s/BS4nHQuAZl2NjQ5TIEJHVg) 一文中已讲到变量挑选和变量降维的过程，完成变量降维后，入模变量的最终挑选和模型评估是确保模型性能、稳定性和业务可解释性的关键步骤。本期还是从业务实际的角度来讨论，介绍入模变量的挑选步骤和注意事项，以及模型评估的指标和业务解释，指标不从复杂公式的角度切入，主要从业务角度理解。

本期主要涉及以下两部分内容，指标涉及KS，AUC，Lift值，PSI等：

1. 模型开发：入模变量挑选过程
2. 模型评估：评估指标及业务解释
   
    - KS指标：正负区分能力
    - AUC指标：排序能力
    - PSI指标：稳定性指标
    - Lift指标：决策指标，用于指导策略动作

<!-- more -->

## 1. 模型开发

模型开发实际上是 **变量挑选** 和 **变量处理** 的过程，当然还有模型 **参数调优**。在完成变量特征的初步降维后，我们得到的是一份“候选变量集”，接下来的目标是从这个集合中挑选出最终入模的变量组合。本期主要是以常用的逻辑回归评分卡模型的角度来讨论，其他机器学习模型过程类似，只是会增加模型参数调优步骤。

在信贷领域，评分模型强调稳定性和可解释性，逐步回归和基于业务知识的专家判断结合是最常用的变量筛选方法，具体流程可按以下步骤进行：

### 1.1 单变量分析

在变量降维环节时虽然已经做过判断，但在模型开发阶段需对变量做再次确认：

**检查IV值**：确保每个候选变量的IV值都达到一定标准，通常是 ==IV>0.02==，剔除 IV 值过低的变量；

**检查缺失率**：剔除缺失率过高的变量，除非该变量非常重要且缺失本身有业务意义。模型开发阶段，候选变量已经非常少，可以针对缺失率较高的变量逐个检查缺失是否具有业务意义。

**检查单一值**：逻辑回归模型开发是用 WOE 分箱转换后的值开发模型，如果WOE分箱个数过少，且大部分样本集中在某一个分箱，取值过于集中，这种类型的变量可以考虑不优先采用，变量影响的只是很小一部分样本。但是如果样本很小的那个分箱区分度特别明显，业务意义清晰，可以考虑采用。

### 1.2 相关性分析

这主要是考虑多重共性线的问题，可以通过计算变量之间的相关性，或者方差膨胀因子（**VIF**）来判断共性线的问题。对于相关性高的多个变量，选择 IV 值最高、WOE 单调性最好、业务意义最明确的变量保留。通常情况下也可以逐个变量测试看模型效果，保留模型效果最好的那个变量即可。

### 1.3 逐步回归

还可以基于逐步回归（如 Python 中的 statsmodels 库）进行入模变量的初步筛选，统计软件一般情况下会帮我们初步筛选 8-20 个变量组合，基于这些初筛的变量，下一步进行最后的变量调优和删减变量。

### 1.4 基于业务理解对变量组合调优与分箱调整

这是最关键的一步，在这一步需确保变量的稳定性、可解释性和业务含义。

**WOE 分箱边界调整**：为了确保变量的稳定性，不容易因分箱边界导致的波动，通常做法是把边界值取整。如负债变量，自动分箱结果其中一个分箱为【0，108976】，取整即是调整为【0，110000】，这样就不容易受到负债增加几块钱导致的取值波动。

**WOE 分箱合并与拆分**：对于分箱虽有单调性，但是区分效果不大的，比如坏账率 10% 和 10.5% 的两个分箱，虽然有单调性，但两者区分度不大，根据实际情况看是否需要合并，通常是建议合并；另外，对于某一个分箱样本占比过大的，也可尝试进一步拆分分箱，评估拆分后是否仍有单调性。

同一批样本，每个建模人员开发的模型都不同，主要就是体现在每个人的分箱习惯不同，以及变量挑选不同；即使同样的变量组合，分箱不同也会导致不一样的模型效果。

**变量可解释性**：确保每个变量都是有业务意义的，并能讲出“为什么这个变量能预测风险”的故事。变量有业务意义还有另一层体现，即 WOE 单调的方向和业务是一致的，比如负债越高，风险越高，这比较符合业务常识，如果是反过来，负债越高风险越低，这就不符合业务常识了，在通用模型中不能使用这类变量。

**稳定性考虑**：这里的稳定性指的是数据源稳定、定义清晰、不易被人为“刷”的变量，优先选择那些稳定性较好的变量。

**模型系数符号检查**：系数符号的正负将影响到下一步的具体打分。还是以上面负债变量为例，负债越高风险越高，即 WOE 值为负，此时转换为评分后分数就应该越低，根据 Python 的 statsmodels 库开发的逻辑回归模型，变量的系数为负才有业务意义。如果为正则业务意义相反，需剔除（这涉及到概率转评分条件的设定，将在下期讨论概率转评分卡的内容）。


### 1.5 评估变量在开发样本、训练样本、OOT样本上的效果

即评估三个样本的变量 IV 值、PSI、WOE 单调性是否一致，挑选三个样本均一致的变量入模，通常开发的模型在后续的模型评估上也是稳定和效果一致的。**但这一方法存在争议，等做完模型开发流程这一系列后再单独讲。**

模型开发中入模变量的选择可以通过以上步骤和方法做入模变量挑选组合，通过变量的组合使模型的 KS 指标和 AUC 指标达到最优。

以上适用于逻辑回归模型，机器学习模型可通过上一期变量降维后的候选变量做多轮的模型训练，反复训练把变量重要性为 0 的剔除，这样也能达到变量挑选的目的。

### 1.6 小结

总结模型变量的挑选，需要注意以下事项：

1. **防止过拟合**
    1. 不要在变量选择上过于追求模型在训练集上的表现，确保在验证集和 OOT 上依然有效；
    2. 变量不是越多越好，通常一个成熟的信用评分卡模型，入模变量在 8-15个 左右为宜，过多的变量会增加模型复杂度和不稳定性；变量过少会导致模型学习到的信息较少。

2. **逻辑回归的线性假设**：逻辑回归假设自变量与 log(odds) 之间存在线性关系，对于连续变量，需要通过分箱来优化其与目标之间的非线性关系（这也是为什么常用 WOE 分箱的原因），在挑选变量时，应使用分箱后的WOE值入模。

3. **业务逻辑优先**：一个统计上显著但业务上无法解释的变量是危险的，它可能只是数据中的偶然，在未来可能会失效，永远选择业务逻辑纯粹的统计指标。

4. **未来数据可用性**：确保挑选的变量在未来模型部署和上线后，能够稳定、及时地获取到，如果某个变量来自一个即将下线的数据源，则不应入选。

5. **变量组合覆盖的全面性**：即挑选变量组合时，变量组合应覆盖所有的维度，如开发人行征信模型，入模变量应覆盖负债、查询、还款历史、额度使用情况、其他机构额度评价、资产情况等等所有维度，让模型尽量能学习到样本的所有维度信息。

## 2. 模型评估指标

模型开发完成后，需要从多个维度（KS/AUC/PSI/Lift）进行全面评估，评估应分别在训练集、测试集和跨时间窗口（OOT）样本上进行，以检验模型的泛化能力和稳定性。

### 2.1 KS：区分能力指标

KS 代表的是模型 “最佳区分点” 的区分能力，代表了模型分数在好坏客户两个群体中分布的最大差距，这个值帮助我们找到区分好坏客户的最佳临界分数点。

![](https://mingminyu.github.io/webassets/images/20250901/01.png)

以上即为好客户与坏客户累计分布的 KS 图，垂直线距离即为 KS 值 29.587%。可以看出，KS 对应的分数点是472 分，对应的坏客户占比是 50%，好客户占比是 20.413%。

在 472 这个分数点，模型捕获到的坏客户比例比捕获到的好客户比例高出 29.587 个百分点，如果把这个分数以下的客户全部拒绝，可以拒掉 50% 的坏客户，代价是误拒 20% 的好客户；

- **如果把这个分数点右移**，即 485 分以下全部拒绝，可以拒掉 65% 的坏客户，代价是误拒 40% 的好客户。从 472 到 485，坏客户增加 15%，好客户却增加了 20%，误拒的好客户边际增加更多，性价比下降了。

- **如果把这个分数点左移**，即 470 分以下全部拒绝，可以拒掉 43.33% 的坏客户，代价是误拒 16.64% 的好客户，虽然拒绝的好客户减少了，但是捕获到的坏客户也少了，放过了更多的坏客户。

所以，KS 值代表的是捕获坏客户的能力比误拒好客户的能力强多少，取到 KS 值的这个分数点就是捕获尽可能多坏客户的前提下，误杀好客户的概率是最低的。分数点往右，误拒好客户的边际增加得比坏客户多；分数点往左，放过的坏客户就变多了。

KS 值的计算步骤：MAX(好客户累计占比– 坏客户累计占比)

1. 评分从低到高排序，或按低到高分箱
2. 计算每个分箱的好坏客户数量及累计占比
3. 计算每个分箱的KS值
4. 对第三步的KS值取max，即为评分的KS值

![](https://mingminyu.github.io/webassets/images/20250901/02.png)

取 MAX 时 KS 值为 29.89%。

一般情况下，KS>=0.2 才具有一定的区分能力，小于 0.2 区分能力较弱。

- KS 越高，意味着能在误拒同样多好客户的情况下，抓住更多的坏客户；或者说，在抓住同样多坏客户的情况下，误拒的好客户更少。
- KS 越低，意味着面临的是一个更痛苦的权衡：抓坏必伤好，放好必放坏。

### 2.2 AUC：排序能力指标

AUC 代表模型的 “排序能力”，AUC 表示随机抽取一个好客户和一个坏客户，模型给这个好客户评分高于这个坏客户分数的概率，即有多大程度确保好客户的分数高到坏客户。例如 AUC = 0.8 意味着，模型有 80% 的概率确保一个好客户分数比一个坏客户分数高。

一个好的模型，坏客户的评分理应比好客户低，表现在评分分布上，坏客户的评分大部分集中在低分数段，好客户的评分大部分集中在高分数段。

AUC值达到多少算好，以下可以参考：

- AUC=0.5（无用模型）：模型没有任何区分能力，其排序效果和抛硬币没有任何区别；
- AUC=0.7-0.8（有用模型）：模型具备了不错的区分能力，已经可以投入到业务中使用，能够有效提升风险区分度；
- AUC=0.8-0.9（优秀模型）：模型具备了很强的区分能力，能极大助力风控策略。但也需要防止是否过拟合；
- AUC=1.0（完美模型）：理论上存在，现实中不可能达到。如果达到，意味着模型完全精准地分开了所有好坏客户，没有任何错误。

以下是一个 ROC 曲线图，正方形的右下角，AUC=0.5，说明没有排序效果；左上角，AUC=1，完美模型，现实中不存在；红线和蓝线分别为训练样本与验证样本的 ROC 曲线，面积分别为 0.69 和 0.68。

![](https://mingminyu.github.io/webassets/images/20250901/03.png)

关于 AUC 值的计算，AUC 值是 ROC 曲线下的面积，而 ROC 曲线是坏客户比率（TPR） 和好客户比率（FPR） 在不同阈值下绘制的。要计算面积比较复杂，不过 AUC 表示的是好客户评分高于坏客户的概率，可以通过计算样本中好客户评分高于坏客户评分的个数，从而计算个数的比率近似得到AUC值，目前在各大统计软件中都有计算AUC的函数，这里不再对 AUC 的具体计算展开。

### 2.3 PSI：稳定性指标

PSI衡量的是评分或变量的分布是否有偏移，在上一期【风控模型专题：一文了解模型变量特征工程】已有讲到，这里不再重复，有兴趣可以看上一期文章的相关部分。

### 2.4 Lift：决策指标

Lift 是衡量模型策略的“效率提升倍数”，是对部分客户的评价。Lift值（例如 Lift=3）表示的是，在使用模型挑选最危险的客户群体时，可以发现坏客户的“浓度”是随机选择客户的 3 倍。

可以用一个业务场景来进一步理解：

1. **基准线（Baseline-不用模型）**：假设我们业务的整体坏客户率是 5%。这意味着，如果随机地从所有客户中抽 100 个人，那预期会找到 5 个坏客户；

2. **模型策略（Using the Model）**：现在，我们让模型对所有客户打分，并选出分数最低的（即最危险的）10% 的客户。

3. **计算Lift**：我们分析这最危险的 10% 的客户群体。

假设在这个群体里，坏客户率不是 5%，**而是 15%**。Lift=模型筛选出的群体坏客户率 / 总体坏客户率也就是：**Lift=15%/5%=3**

因此，`Lift=3` 的业务意义是：我们的模型非常精准！如果我们把精力聚焦在模型识别出的最危险的前 10% 的客户上，我们寻找坏客户的效率将是漫无目的随机抽查的 3 倍。这就像是给了我们的风控团队一个‘精准雷达’和坐标，决策上可以做到定点清除。

策略团队往住不仅关心“最坏的一部分有多坏”，更关心“模型的整体排序能力是否稳定”。因此，我们通常不会只看一个点（比如前 10%）的 Lift，而是绘制 Lift Chart（提升图）看排序能力差异，AUC 衡量整体排序，但是在衡量风险高低上还不够具体，提升图可以做到这一点。

还是以 KS 中的例子举例，例子里已经计算好 Lift 值，提升图如下：

![](https://mingminyu.github.io/webassets/images/20250901/04.png)

对于这个提升图，可以这样解读：

- **前三分箱（最高风险组）**：Lift值最高，达到了3。这意味着这群人的坏账风险是平均水平的3倍！模型成功地把‘精华’（最坏的客户）浓缩在了最前面。

- **随着风险降低，Lift 值单调下降**：这是一个好模型的标志，说明排序能力很稳定。510 分以上，Lift 值只有 0.28，说明只有平均风险水平的 30% 不到，是优质的客户。

- **模型的威力**：它不仅仅找到了最高风险的那一群人，而且实现了完美的风险分层。

Lift 值能找到风险最高的那一小部分人，同时还实现了风险分层，它告诉我们应该把有限的资源（如人工审核精力、严格的催收策略、营销预算等）投入到哪里，才能实现效率最大化。它是一个很好的决策指标，精准定位人群，指导决策动作。

模型评估，即在训练样本开发完模型后，需要在验证样本、OOT 样本上评估 KS、AUC、PSI、Lift 值的差异，在三个样本上这些指标要差异很小，模型才算开发完成，说明模型泛化能力较强，稳定性较好。除了模型整体评估外，还需要对入模变量进行以下评估，确保变量稳定，客群没有发生迁移：

1. **入模变量稳定性评估**：即三个样本每个变量的 PSI 均较小，变量稳定。

2. **入模变量WOE评估**：即三个样本每个变量的 WOE 单调趋势一致，变量区分度没有发生改变，趋势没有反转。更进一步可以参考Lift有没有发生较大变化，评估区分能力有没有下降。

关于模型评估指标KS/AUC/Lift/PSI业务含义总结如下：

| 指标 | 整体解释 | 业务含义 |
| ---- | -------- | -------- |
| KS   | 区分能力，单个分数点 | KS 值代表的是捕获坏客户的能力比误拒好客户的能力强多少，取到 KS 值的这个分数点就是捕获较尽可能多坏客户的前提下，误杀好客户的概率是最低的。分数点往右，误拒好客户的边际增加得比坏客户多；分数点往左，放过的坏客户就变多了。 |
| AUC  | 排序能力，整体样本 | AUC 值表示随机抽取一个好客户和一个坏客户，模型给这个好客户评分高于这个坏客户分数的概率。 |
| Lift | 效率提升倍数，局部样本 | Lift 是衡量模型策略的“效率提升倍数”，是对部分客户的评价。Lift 值表示的是，在使用模型挑选某一部分客户群体时，坏客户的“浓度”是整体样本中坏客户的多少倍。 |
| PSI  | 群体偏移评估 | 衡量两个不同的样本是否发生偏移，客户是否显著发生变化。 |

